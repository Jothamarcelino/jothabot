import os
import re
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.schema import Document

# Diret√≥rio com os PPCs
DIRETORIO_PLANOS = "data/planos"
SAIDA_VECTORSTORE = "vectorstore/planos_index"

# Fun√ß√£o para detectar automaticamente o nome do curso
def extrair_nome_do_curso(texto: str) -> str:
    texto = texto.replace("\n", " ").replace("  ", " ").upper()

    padroes = [
        r"T[√âE]CNICO EM ((?:[A-Z√Ä-≈∏]{2,}(?: [A-Z√Ä-≈∏]{2,}){0,5}))",
        r"BACHARELADO EM ((?:[A-Z√Ä-≈∏]{2,}(?: [A-Z√Ä-≈∏]{2,}){0,5}))",
        r"LICENCIATURA EM ((?:[A-Z√Ä-≈∏]{2,}(?: [A-Z√Ä-≈∏]{2,}){0,5}))",
        r"GRADUA√á√ÉO EM ((?:[A-Z√Ä-≈∏]{2,}(?: [A-Z√Ä-≈∏]{2,}){0,5}))",
        r"TECNOLOGIA EM ((?:[A-Z√Ä-≈∏]{2,}(?: [A-Z√Ä-≈∏]{2,}){0,5}))",
        r"CURSO DE ((?:[A-Z√Ä-≈∏]{2,}(?: [A-Z√Ä-≈∏]{2,}){0,5}))",
        r"CURSO SUPERIOR EM ((?:[A-Z√Ä-≈∏]{2,}(?: [A-Z√Ä-≈∏]{2,}){0,5}))",
        r"PROJETO PEDAG[√ìO]GICO DO CURSO DE ((?:[A-Z√Ä-≈∏]{2,}(?: [A-Z√Ä-≈∏]{2,}){0,5}))",
    ]

    for padrao in padroes:
        match = re.search(padrao, texto)
        if match:
            nome = match.group(1).strip()

            # Remo√ß√£o de sufixos irrelevantes
            lixo = [
                "MODALIDADE", "CAMPUS", "PROJETO", "INSTITUTO",
                "COORDENADOR", "PROFESSOR", "REITOR",
                "DEPARTAMENTO", "N√öCLEO", "UNIDADE"
            ]
            for palavra in lixo:
                if palavra in nome:
                    nome = nome.split(palavra)[0].strip()

            return nome.lower().replace(" ", "_")

    # Fallback: busca por termos conhecidos
    termos_famosos = ["AGRONOMIA", "TURISMO", "QU√çMICA", "COMPUTA√á√ÉO", "ENFERMAGEM", "ALIMENTOS"]
    for termo in termos_famosos:
        if termo in texto:
            return termo.lower().replace(" ", "_")

    return "desconhecido"

# Inicializa embeddings
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

# Coleta documentos vetorizados
todos_chunks = []

for nome_arquivo in os.listdir(DIRETORIO_PLANOS):
    caminho = os.path.join(DIRETORIO_PLANOS, nome_arquivo)
    if not nome_arquivo.endswith(".pdf"):
        continue

    print(f"üìÑ Lendo {nome_arquivo}...")

    loader = PyPDFLoader(caminho)
    docs = loader.load()

    # Usa as 2 primeiras p√°ginas para detectar o nome do curso
    primeiras_paginas = " ".join([doc.page_content for doc in docs[:2]])
    nome_curso = extrair_nome_do_curso(primeiras_paginas)
    print(f"üîç Curso identificado: {nome_curso}")

    # Adiciona metadado do curso
    for doc in docs:
        doc.metadata["curso"] = nome_curso

    splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    chunks = splitter.split_documents(docs)
    todos_chunks.extend(chunks)

# Cria a base vetorial
print("‚öôÔ∏è Gerando base vetorial dos planos...")
db = FAISS.from_documents(todos_chunks, embedding=embeddings)
db.save_local(SAIDA_VECTORSTORE)
print("‚úÖ Vetoriza√ß√£o dos Planos de Curso conclu√≠da com metadados autom√°ticos!")