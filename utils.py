import os
import pandas as pd
import streamlit as st
from groq import Groq
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_huggingface import HuggingFaceEmbeddings

# Tenta carregar vetor com tratamento de erro
def tentar_carregar_retriever(path):
    try:
        embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
        retriever = FAISS.load_local(path, embeddings, allow_dangerous_deserialization=True).as_retriever()
        return retriever
    except Exception as e:
        print(f"‚ö†Ô∏è N√£o foi poss√≠vel carregar vetores de: {path} ‚Üí {e}")
        return None

# Carrega os tr√™s reposit√≥rios vetoriais (FAQ, Leis, PPCs)
retriever_faq = tentar_carregar_retriever("vectorstore/faq_index")
retriever_pdf = tentar_carregar_retriever("vectorstore/legal_index")
retriever_planos = tentar_carregar_retriever("vectorstore/planos_index")

# Cliente Groq com fallback para secrets
client = Groq(api_key=os.environ.get("GROQ_API", st.secrets["GROQ_API"]))

# Fun√ß√£o principal de resposta
def responder_usuario(pergunta):
    if not retriever_faq and not retriever_pdf and not retriever_planos:
        return (
            "‚ö†Ô∏è Os arquivos vetoriais ainda n√£o foram carregados. "
            "Acesse a aba 'Files' e envie as pastas `vectorstore/faq_index/`, `legal_index/` e `planos_index/`. "
            "Depois clique em 'Rerun'.", False
        )

    # üîç Prioriza FAQ
    docs_faq = retriever_faq.get_relevant_documents(pergunta)[:1] if retriever_faq else []

    if docs_faq:
        contexto = "\n\n".join([doc.page_content for doc in docs_faq])
    else:
        # Caso FAQ n√£o encontre, busca nas leis e planos
        docs_pdf = retriever_pdf.get_relevant_documents(pergunta)[:1] if retriever_pdf else []
        docs_planos = retriever_planos.get_relevant_documents(pergunta)[:1] if retriever_planos else []

        if not docs_pdf and not docs_planos:
            return ("ü§î Hmm... n√£o encontrei nada sobre isso nos meus arquivos. Mas j√° registrei sua d√∫vida! üòâ", False)

        contexto = "\n\n".join([doc.page_content for doc in docs_pdf + docs_planos])

    # üîí Limita tamanho
    contexto = contexto[:15000]

    # üß† Prompt refor√ßado
    prompt = f"""
Voc√™ √© o JOTHA, assistente virtual da Coordena√ß√£o de Est√°gio do IF Sudeste MG - Campus Barbacena.

Responda com simpatia, clareza e **base apenas no contexto abaixo**. N√£o invente, n√£o complemente e n√£o improvise.  
Seja √∫til e direto, mas mantenha um tom acolhedor e divertido.

‚ö†Ô∏è Regras:
- Use exatamente o que estiver no contexto, especialmente se houver HTML.
- Se n√£o encontrar resposta, diga que n√£o encontrou e oriente o usu√°rio a procurar a Coordena√ß√£o de Est√°gio.

Contexto:
{contexto}

Pergunta:
{pergunta}

Resposta:
"""

    response = client.chat.completions.create(
        model="llama3-8b-8192",
        messages=[
            {"role": "system", "content": "Voc√™ responde em portugu√™s, com gentileza, precis√£o e sem inventar informa√ß√µes."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.3,
        max_tokens=512
    )

    return response.choices[0].message.content.strip(), True

# Registra perguntas n√£o respondidas
def registrar_pergunta_nao_respondida(pergunta):
    arquivo = "nao_respondidas.csv"
    if os.path.exists(arquivo):
        df = pd.read_csv(arquivo)
    else:
        df = pd.DataFrame(columns=["pergunta"])

    nova_linha = pd.DataFrame([{"pergunta": pergunta}])
    df = pd.concat([df, nova_linha], ignore_index=True)
    df.to_csv(arquivo, index=False)